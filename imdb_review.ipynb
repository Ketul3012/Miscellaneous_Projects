{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data , train_label) , (test_data , test_label) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {k:(v+3) for k,v in word_index.items()} \n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2 \n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_dic = dict([(value,key) for (key,value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text(text):\n",
    "    return ' '.join([reverse_word_dic.get(i,'?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_text(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = 10000\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.leaky_relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = train_data[:10000]\n",
    "partial_x_train = train_data[10000:]\n",
    "\n",
    "y_val = train_label[:10000]\n",
    "partial_y_train = train_label[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/60\n",
      "15000/15000 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.521 - 3s 211us/step - loss: 0.6916 - acc: 0.5228 - val_loss: 0.6894 - val_acc: 0.5658\n",
      "Epoch 2/60\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.6845 - acc: 0.6859 - val_loss: 0.6793 - val_acc: 0.7432\n",
      "Epoch 3/60\n",
      "15000/15000 [==============================] - 1s 44us/step - loss: 0.6683 - acc: 0.7679 - val_loss: 0.6584 - val_acc: 0.7632\n",
      "Epoch 4/60\n",
      "15000/15000 [==============================] - 1s 42us/step - loss: 0.6387 - acc: 0.7825 - val_loss: 0.6257 - val_acc: 0.7727\n",
      "Epoch 5/60\n",
      "15000/15000 [==============================] - 1s 43us/step - loss: 0.5962 - acc: 0.8067 - val_loss: 0.5816 - val_acc: 0.7956\n",
      "Epoch 6/60\n",
      "15000/15000 [==============================] - 1s 42us/step - loss: 0.5457 - acc: 0.8227 - val_loss: 0.5347 - val_acc: 0.8124\n",
      "Epoch 7/60\n",
      "15000/15000 [==============================] - 1s 42us/step - loss: 0.4933 - acc: 0.8408 - val_loss: 0.4890 - val_acc: 0.8260\n",
      "Epoch 8/60\n",
      "15000/15000 [==============================] - 1s 42us/step - loss: 0.4444 - acc: 0.8558 - val_loss: 0.4484 - val_acc: 0.8393\n",
      "Epoch 9/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.4020 - acc: 0.8673 - val_loss: 0.4145 - val_acc: 0.8487\n",
      "Epoch 10/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.3655 - acc: 0.8800 - val_loss: 0.3872 - val_acc: 0.8574\n",
      "Epoch 11/60\n",
      "15000/15000 [==============================] - ETA: 0s - loss: 0.3358 - acc: 0.8883- ETA: 0s - loss: 0.3457 - acc: - 1s 41us/step - loss: 0.3357 - acc: 0.8875 - val_loss: 0.3674 - val_acc: 0.8597\n",
      "Epoch 12/60\n",
      "15000/15000 [==============================] - 1s 42us/step - loss: 0.3112 - acc: 0.8957 - val_loss: 0.3481 - val_acc: 0.8679\n",
      "Epoch 13/60\n",
      "15000/15000 [==============================] - 1s 41us/step - loss: 0.2888 - acc: 0.9013 - val_loss: 0.3349 - val_acc: 0.8704\n",
      "Epoch 14/60\n",
      "15000/15000 [==============================] - 1s 43us/step - loss: 0.2703 - acc: 0.9077 - val_loss: 0.3233 - val_acc: 0.8742\n",
      "Epoch 15/60\n",
      "15000/15000 [==============================] - ETA: 0s - loss: 0.2543 - acc: 0.912 - 1s 42us/step - loss: 0.2543 - acc: 0.9129 - val_loss: 0.3146 - val_acc: 0.8771\n",
      "Epoch 16/60\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.2404 - acc: 0.9165 - val_loss: 0.3074 - val_acc: 0.8784\n",
      "Epoch 17/60\n",
      "15000/15000 [==============================] - 1s 45us/step - loss: 0.2269 - acc: 0.9233 - val_loss: 0.3016 - val_acc: 0.8794\n",
      "Epoch 18/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.2152 - acc: 0.9262 - val_loss: 0.2970 - val_acc: 0.8819\n",
      "Epoch 19/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.2042 - acc: 0.9297 - val_loss: 0.2934 - val_acc: 0.8826\n",
      "Epoch 20/60\n",
      "15000/15000 [==============================] - 1s 42us/step - loss: 0.1947 - acc: 0.9347 - val_loss: 0.2904 - val_acc: 0.8832\n",
      "Epoch 21/60\n",
      "15000/15000 [==============================] - 1s 42us/step - loss: 0.1853 - acc: 0.9387 - val_loss: 0.2884 - val_acc: 0.8848\n",
      "Epoch 22/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.1766 - acc: 0.9425 - val_loss: 0.2871 - val_acc: 0.8845\n",
      "Epoch 23/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.1688 - acc: 0.9466 - val_loss: 0.2866 - val_acc: 0.8838\n",
      "Epoch 24/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.1609 - acc: 0.9497 - val_loss: 0.2856 - val_acc: 0.8851\n",
      "Epoch 25/60\n",
      "15000/15000 [==============================] - ETA: 0s - loss: 0.1543 - acc: 0.952 - 1s 40us/step - loss: 0.1540 - acc: 0.9523 - val_loss: 0.2856 - val_acc: 0.8859\n",
      "Epoch 26/60\n",
      "15000/15000 [==============================] - 1s 43us/step - loss: 0.1470 - acc: 0.9551 - val_loss: 0.2864 - val_acc: 0.8864\n",
      "Epoch 27/60\n",
      "15000/15000 [==============================] - 1s 41us/step - loss: 0.1412 - acc: 0.9569 - val_loss: 0.2877 - val_acc: 0.8853\n",
      "Epoch 28/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.1350 - acc: 0.9603 - val_loss: 0.2880 - val_acc: 0.8868\n",
      "Epoch 29/60\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.1295 - acc: 0.9607 - val_loss: 0.2893 - val_acc: 0.8870\n",
      "Epoch 30/60\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.1245 - acc: 0.9635 - val_loss: 0.2913 - val_acc: 0.8863\n",
      "Epoch 31/60\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.1186 - acc: 0.9657 - val_loss: 0.2935 - val_acc: 0.8866\n",
      "Epoch 32/60\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.1141 - acc: 0.9679 - val_loss: 0.2961 - val_acc: 0.8861\n",
      "Epoch 33/60\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.1088 - acc: 0.9701 - val_loss: 0.2988 - val_acc: 0.8851\n",
      "Epoch 34/60\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.1045 - acc: 0.9712 - val_loss: 0.3021 - val_acc: 0.8834\n",
      "Epoch 35/60\n",
      "15000/15000 [==============================] - ETA: 0s - loss: 0.1005 - acc: 0.973 - 1s 40us/step - loss: 0.1005 - acc: 0.9736 - val_loss: 0.3044 - val_acc: 0.8840\n",
      "Epoch 36/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.0958 - acc: 0.9743 - val_loss: 0.3081 - val_acc: 0.8829\n",
      "Epoch 37/60\n",
      "15000/15000 [==============================] - ETA: 0s - loss: 0.0923 - acc: 0.975 - 1s 40us/step - loss: 0.0920 - acc: 0.9760 - val_loss: 0.3115 - val_acc: 0.8823\n",
      "Epoch 38/60\n",
      "15000/15000 [==============================] - ETA: 0s - loss: 0.0893 - acc: 0.977 - 1s 39us/step - loss: 0.0886 - acc: 0.9771 - val_loss: 0.3161 - val_acc: 0.8806\n",
      "Epoch 39/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.0846 - acc: 0.9787 - val_loss: 0.3188 - val_acc: 0.8811\n",
      "Epoch 40/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.0809 - acc: 0.9801 - val_loss: 0.3230 - val_acc: 0.8816\n",
      "Epoch 41/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.0780 - acc: 0.9810 - val_loss: 0.3282 - val_acc: 0.8799\n",
      "Epoch 42/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.0746 - acc: 0.9823 - val_loss: 0.3314 - val_acc: 0.8805\n",
      "Epoch 43/60\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.0715 - acc: 0.9842 - val_loss: 0.3360 - val_acc: 0.8803\n",
      "Epoch 44/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.0682 - acc: 0.9849 - val_loss: 0.3423 - val_acc: 0.8784\n",
      "Epoch 45/60\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.0658 - acc: 0.9859 - val_loss: 0.3469 - val_acc: 0.8787\n",
      "Epoch 46/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.0631 - acc: 0.9869 - val_loss: 0.3511 - val_acc: 0.8789\n",
      "Epoch 47/60\n",
      "15000/15000 [==============================] - ETA: 0s - loss: 0.0593 - acc: 0.988 - 1s 40us/step - loss: 0.0599 - acc: 0.9879 - val_loss: 0.3563 - val_acc: 0.8777\n",
      "Epoch 48/60\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.0579 - acc: 0.9884 - val_loss: 0.3627 - val_acc: 0.8773\n",
      "Epoch 49/60\n",
      "15000/15000 [==============================] - ETA: 0s - loss: 0.0556 - acc: 0.988 - 1s 41us/step - loss: 0.0552 - acc: 0.9890 - val_loss: 0.3666 - val_acc: 0.8769\n",
      "Epoch 50/60\n",
      "15000/15000 [==============================] - ETA: 0s - loss: 0.0528 - acc: 0.989 - 1s 39us/step - loss: 0.0526 - acc: 0.9899 - val_loss: 0.3711 - val_acc: 0.8772\n",
      "Epoch 51/60\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.0503 - acc: 0.9906 - val_loss: 0.3776 - val_acc: 0.8782\n",
      "Epoch 52/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.0484 - acc: 0.9909 - val_loss: 0.3833 - val_acc: 0.8766\n",
      "Epoch 53/60\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.0463 - acc: 0.9919 - val_loss: 0.3893 - val_acc: 0.8758\n",
      "Epoch 54/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.0442 - acc: 0.9923 - val_loss: 0.3945 - val_acc: 0.8749\n",
      "Epoch 55/60\n",
      "15000/15000 [==============================] - 1s 40us/step - loss: 0.0421 - acc: 0.9928 - val_loss: 0.3999 - val_acc: 0.8760\n",
      "Epoch 56/60\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.0404 - acc: 0.9933 - val_loss: 0.4053 - val_acc: 0.8741\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.0386 - acc: 0.9939 - val_loss: 0.4133 - val_acc: 0.8718\n",
      "Epoch 58/60\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.0370 - acc: 0.9942 - val_loss: 0.4174 - val_acc: 0.8744\n",
      "Epoch 59/60\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.0353 - acc: 0.9945 - val_loss: 0.4239 - val_acc: 0.8721\n",
      "Epoch 60/60\n",
      "15000/15000 [==============================] - 1s 39us/step - loss: 0.0338 - acc: 0.9951 - val_loss: 0.4311 - val_acc: 0.8709\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=60,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 47us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46178459196567534, 0.85856]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
